{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "#from vidstab import VidStab\n",
    "from os import listdir\n",
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "import skimage \n",
    "from skimage import data, color\n",
    "from skimage.transform import hough_circle, hough_circle_peaks\n",
    "from skimage.feature import canny\n",
    "from skimage.draw import circle_perimeter\n",
    "from progressbar import ProgressBar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Helper Methods \n",
    "def last_4chars(x):\n",
    "    suf = x.split(\"_\")[1]\n",
    "    inte = int(suf.split(\".\")[0])\n",
    "    return inte\n",
    "\n",
    "def getFrame(sec,path,stable_vid_name,count):\n",
    "    vidcap = cv2.VideoCapture(stable_vid_name)\n",
    "    vidcap.set(cv2.CAP_PROP_POS_MSEC,sec*1000)\n",
    "    hasFrames,image = vidcap.read()\n",
    "    if hasFrames:\n",
    "        cv2.imwrite(path+\"/image_\"+str(count)+\".jpg\", image)     # save frame as JPG file\n",
    "    return hasFrames\n",
    "\n",
    "    \n",
    "def list_files1(directory, extension):\n",
    "    \"\"\"\n",
    "    list_files1: Find files with a certain extension in the directory and return the names in a list\n",
    "            Args:\n",
    "                directory: Directory to be searched\n",
    "                extension: the extension of the files\n",
    "            Returns:\n",
    "                List of files with the extension within the directory\n",
    "    \"\"\"\n",
    "    return list(( (directory + f) for f in listdir(directory) if f.endswith('.' + extension)))\n",
    "\n",
    "def generate_frames_vid():\n",
    "    \"\"\"\n",
    "    generate_frames_vid: Generates frames for every video in listvideos, and save them in folder with\n",
    "                         name vidName/\n",
    "                    Args:\n",
    "                        listvideos: List containing the path to the video files\n",
    "                    Returns:\n",
    "                        None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        os.mkdir(\"StableFrames\", 755)\n",
    "    except OSError:\n",
    "        pass\n",
    "    try:\n",
    "        os.mkdir(\"StableFrames/videos\", 755)\n",
    "    except OSError:\n",
    "        pass\n",
    "    listvideos = list_files1('videos/','avi')\n",
    "    for video in listvideos:\n",
    "        path = \"StableFrames/\" + video.split('.avi')[0]\n",
    "        try:\n",
    "            os.mkdir(path, 755)\n",
    "        except OSError:\n",
    "            pass\n",
    "        stable_vid_name = 'stable_video.avi'\n",
    "        stabilizer = VidStab(kp_method='GFTT')\n",
    "        stabilizer.stabilize(input_path=video, output_path=stable_vid_name)\n",
    "        sec = 0\n",
    "        frameRate = 0.5 #//it will capture image in each 0.5 second\n",
    "        count=1\n",
    "        success = getFrame(sec,path,stable_vid_name,count)\n",
    "        while success:\n",
    "            count = count + 1\n",
    "            sec = sec + frameRate\n",
    "            sec = round(sec, 2)\n",
    "            success = getFrame(sec,path,stable_vid_name,count)\n",
    " \n",
    "### Generate train_test data\n",
    "def generate_train_testdata(k):\n",
    "    \"\"\"\n",
    "    generate_train_testdata: Generate table for path to input and output data\n",
    "                        Args:\n",
    "                            k: Distance for the next frame\n",
    "                        Returns:\n",
    "                             df containg the input path and the corresponding output predicted\n",
    "    \"\"\"\n",
    "    data = pd.DataFrame(columns=[\"input\", \"output\"])\n",
    "    directory = \"StableFrames/videos\"\n",
    "    subdir = listdir(directory)\n",
    "    for subd in subdir:\n",
    "        images = sorted(listdir(directory + \"/\" + subdir[0]), key=last_4chars)\n",
    "        for idx, img in enumerate(images):\n",
    "            base_path = directory + \"/\" + subd + \"/\"\n",
    "            input_img = base_path + img\n",
    "            output_img = base_path + \"image_\" + str(idx+k+1) + \".jpg\"\n",
    "            if os.path.isfile(output_img):\n",
    "                temp_df = pd.DataFrame([[input_img,output_img]], columns=[\"input\", \"output\"])\n",
    "                data =  pd.concat((data,temp_df))\n",
    "    return data     \n",
    "\n",
    "def read_from_path(X):\n",
    "    \"\"\"\n",
    "    read_from_path: Read images from path, preprocess, and append to numpy data frame.\n",
    "                Args:\n",
    "                    X: List containing all the paths\n",
    "                Returns:\n",
    "                    data: numpy array containing all of the data\n",
    "    \"\"\"\n",
    "    img_size = 128\n",
    "    data = np.empty(shape = [1,img_size,img_size])\n",
    "    pbar = ProgressBar()\n",
    "    for i in pbar(X):\n",
    "        img = cv2.imread(i)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        img = preprocess_image(img)\n",
    "        #img = cv2.normalize(img, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "        img = cv2.resize(img, (img_size,img_size))\n",
    "        img = img.reshape(1,img_size,img_size)\n",
    "        data = np.append(data,img, axis = 0)\n",
    "    data = data.reshape(len(X)+1,img_size,img_size,1)\n",
    "    return data\n",
    "\n",
    "def get_best_circle(img1):\n",
    "    \"\"\"\n",
    "    get_best_circle: Use hough transform to find the best circle\n",
    "                Args: \n",
    "                     img1: Grayscale image on which to find the circle\n",
    "                Returns:\n",
    "                    circle: list containing the x-coords, y-coords of the center\n",
    "                            and radius for the circle. \n",
    "    \"\"\"\n",
    "    edges = canny(img1, sigma=2, low_threshold=10, high_threshold=50)\n",
    "    hough_radii = np.arange(50, 150, 2)\n",
    "    hough_res = hough_circle(edges, hough_radii)\n",
    "    accums, cx, cy, radii = hough_circle_peaks(hough_res, hough_radii,\n",
    "                                               total_num_peaks=3)\n",
    "    max_idx = np.argmax(radii)\n",
    "    max_x = cx[max_idx]\n",
    "    max_y = cy[max_idx]\n",
    "    max_radii = radii[max_idx]\n",
    "    return ([max_x, max_y, max_radii])\n",
    "\n",
    "def preprocess_image(img1):\n",
    "    \"\"\"\n",
    "    preprocess_image: Find the relevant information, and shift to the center\n",
    "    \n",
    "                Args:\n",
    "                    img1: Image on which to perform the preprocessing\n",
    "                Returns:\n",
    "                    masked_img: Image with preprocessing done\n",
    "    \n",
    "    \"\"\"\n",
    "    x_coord, y_coord, radius = get_best_circle(img2)\n",
    "    \n",
    "    height,width = img1.shape\n",
    "    mask = np.zeros((height,width), np.uint8) \n",
    "    x,y = skimage.draw.circle(y_coord,x_coord,radius)\n",
    "    mask[x,y] = 255\n",
    "    masked_data = mask*img1\n",
    "    M = np.float32([[1,0,250-x_coord],[0,1,250-y_coord]])\n",
    "    masked_img = cv2.warpAffine(masked_data,M,(height,width))\n",
    "    return masked_img\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate_frames_vid()\n",
    "train_test_data = generate_train_testdata(1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_decoder(img_size):\n",
    "    model = tf.keras.Sequential()\n",
    "    ###Encoder\n",
    "    model.add(tf.keras.layers.Conv2D(filters = 64, kernel_size = 6,strides=2, padding = \"valid\",\n",
    "                                     activation = \"relu\", input_shape = (img_size,img_size,1),\n",
    "                                     kernel_initializer = tf.keras.initializers.glorot_normal(seed=15),\n",
    "                                     name= \"layer1\"))\n",
    "    model.add(tf.keras.layers.MaxPool2D(3, strides=2, padding=\"valid\", name = \"pool1\"))\n",
    "    model.add(tf.keras.layers.Conv2D(filters =  12, kernel_size = 6,strides=2, padding = \"valid\",\n",
    "                                     activation = \"relu\",\n",
    "                                     kernel_initializer = tf.keras.initializers.glorot_normal(seed=15),\n",
    "                                     name= \"layer2\"))\n",
    "    model.add(tf.keras.layers.MaxPool2D(3, strides=2, padding=\"valid\", name = \"pool2\"))\n",
    "    \n",
    "    model.add(tf.keras.layers.Reshape((1,432)))\n",
    "    model.add(tf.keras.layers.Dense(2, activation = \"relu\", \n",
    "                                    kernel_initializer = tf.keras.initializers.glorot_normal(seed=15)))\n",
    "    model.add(tf.keras.layers.Dense(16384, activation = \"relu\",\n",
    "                                    kernel_initializer = tf.keras.initializers.glorot_normal(seed=15)))\n",
    "    model.add(tf.keras.layers.Reshape((img_size,img_size,1)))\n",
    "    model.summary()\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['mae'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "layer1 (Conv2D)              (None, 62, 62, 64)        2368      \n",
      "_________________________________________________________________\n",
      "pool1 (MaxPooling2D)         (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "layer2 (Conv2D)              (None, 13, 13, 12)        27660     \n",
      "_________________________________________________________________\n",
      "pool2 (MaxPooling2D)         (None, 6, 6, 12)          0         \n",
      "_________________________________________________________________\n",
      "reshape_6 (Reshape)          (None, 1, 432)            0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1, 2)              866       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1, 16384)          49152     \n",
      "_________________________________________________________________\n",
      "reshape_7 (Reshape)          (None, 128, 128, 1)       0         \n",
      "=================================================================\n",
      "Total params: 80,046\n",
      "Trainable params: 80,046\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "### Stabalize and generate images\n",
    "\n",
    "encoder = encoder_decoder(128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with Image StableFrames/videos/D2019.11.14_well6_video/image_1.jpg. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2% |#                                                                       |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with Image StableFrames/videos/D2019.11.14_well6_video/image_2.jpg. \n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-8fba9cecc618>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0minp_d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_from_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mout_d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_from_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-6b7c1729111e>\u001b[0m in \u001b[0;36mread_from_path\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m         \u001b[0;31m#img = cv2.normalize(img, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimg_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimg_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-6b7c1729111e>\u001b[0m in \u001b[0;36mpreprocess_image\u001b[0;34m(img1)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \"\"\"\n\u001b[0;32m--> 140\u001b[0;31m     \u001b[0mx_coord\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_coord\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mradius\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_best_circle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-6b7c1729111e>\u001b[0m in \u001b[0;36mget_best_circle\u001b[0;34m(img1)\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0medges\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcanny\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlow_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhigh_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0mhough_radii\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m     \u001b[0mhough_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhough_circle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medges\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhough_radii\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m     accums, cx, cy, radii = hough_circle_peaks(hough_res, hough_radii,\n\u001b[1;32m    123\u001b[0m                                                total_num_peaks=3)\n",
      "\u001b[0;32m~/miniconda2/lib/python3.6/site-packages/skimage/transform/hough_transform.py\u001b[0m in \u001b[0;36mhough_circle\u001b[0;34m(image, radius, normalize, full_output)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0mradius\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matleast_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mradius\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     return _hough_circle(image, radius.astype(np.intp),\n\u001b[0;32m--> 111\u001b[0;31m                          normalize=normalize, full_output=full_output)\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mskimage/transform/_hough_transform.pyx\u001b[0m in \u001b[0;36mskimage.transform._hough_transform._hough_circle\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/lib/python3.6/site-packages/skimage/draw/draw.py\u001b[0m in \u001b[0;36mcircle_perimeter\u001b[0;34m(r, c, radius, method, shape)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mcircle_perimeter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mradius\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bresenham'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m     \"\"\"Generate circle perimeter coordinates.\n\u001b[1;32m    465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "inp = train_test_data.iloc[:,0].values.tolist()\n",
    "inp_d = read_from_path(inp)\n",
    "out = train_test_data.iloc[:,1].values.tolist()\n",
    "out_d = read_from_path(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoder.fit(x = inp_d, y = out_d, batch_size = 4, epochs=200, validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
