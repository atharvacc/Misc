{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from vidstab import VidStab\n",
    "from os import listdir\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage \n",
    "from skimage import data, color\n",
    "from skimage.transform import hough_circle, hough_circle_peaks\n",
    "from skimage.feature import canny\n",
    "from skimage.draw import circle_perimeter\n",
    "from progressbar import ProgressBar\n",
    "import seaborn as sns\n",
    "from os.path import isfile, join\n",
    "from classifypixelsunet import *\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def last_4chars(x):\n",
    "    suf = x.split(\"_\")[1]\n",
    "    inte = int(suf.split(\".\")[0])\n",
    "    return inte\n",
    "\n",
    "def generate_train_testdata(k):\n",
    "    \"\"\"\n",
    "    generate_train_testdata: Generate table for path to input and output data\n",
    "                        Args:\n",
    "                            k: Distance for the next frame\n",
    "                        Returns:\n",
    "                             df containg the input path and the corresponding output predicted\n",
    "    \"\"\"\n",
    "    data = pd.DataFrame(columns=[\"input\", \"output\"])\n",
    "    directory = \"StableFrames/videos\"\n",
    "    subdir = listdir(directory)\n",
    "    for subd in subdir:\n",
    "        images = sorted(listdir(directory + \"/\" + subdir[0]), key=last_4chars)\n",
    "        for idx, img in enumerate(images):\n",
    "            base_path = directory + \"/\" + subd + \"/\"\n",
    "            input_img = base_path + img\n",
    "            output_img = base_path + \"image_\" + str(idx+k+1) + \".jpg\"\n",
    "            if os.path.isfile(output_img):\n",
    "                temp_df = pd.DataFrame([[input_img,output_img]], columns=[\"input\", \"output\"])\n",
    "                data =  pd.concat((data,temp_df))\n",
    "    return data    \n",
    "\n",
    "\n",
    "def get_vid_data(train_test_data, end_idx):\n",
    "    base_idx = 0\n",
    "    initial_end_idx = end_idx\n",
    "    n_vid = int(train_test_data.shape[0]/end_idx)\n",
    "    new_df = pd.DataFrame()\n",
    "    for i in range(n_vid):\n",
    "        print(i)\n",
    "        new_data = train_test_data.input.iloc[base_idx:end_idx]\n",
    "        new_df = pd.concat((new_df,new_data), axis = 1)\n",
    "        base_idx = end_idx\n",
    "        end_idx = base_idx+initial_end_idx\n",
    "    cols = [\"Video{}\".format(x) for x in range(n_vid) ]\n",
    "    new_df.columns = cols\n",
    "    return new_df\n",
    "\n",
    "def read_data(X):\n",
    "    \"\"\"\n",
    "    read_from_path: Read images from path, preprocess, and append to numpy data frame.\n",
    "                Args:\n",
    "                    X: List containing all the paths\n",
    "                Returns:\n",
    "                    data: numpy array containing all of the data\n",
    "    \"\"\"\n",
    "    new_img_size = 500\n",
    "    data = np.empty(shape = [1,new_img_size,new_img_size])\n",
    "    pbar = ProgressBar()\n",
    "    print(\"Starting Reading and Preprocessing.\\n\")\n",
    "    \n",
    "    for i in pbar(X):\n",
    "        img = cv2.imread(i, 0)\n",
    "        img = img.reshape(1,new_img_size, new_img_size)\n",
    "        data = np.append(data,img, axis = 0)\n",
    "    print(\"Done Reading and Preprocessing.\\n\")\n",
    "    data = data.reshape(len(X)+1,new_img_size,new_img_size,1)\n",
    "    return data\n",
    "\n",
    "\n",
    "def getFrame(sec,path,stable_vid_name,count):\n",
    "    vidcap = cv2.VideoCapture(stable_vid_name)\n",
    "    vidcap.set(cv2.CAP_PROP_POS_MSEC,sec*1000)\n",
    "    hasFrames,image = vidcap.read()\n",
    "    if hasFrames:\n",
    "        cv2.imwrite(path+\"/image_\"+str(count)+\".jpg\", image)     # save frame as JPG file\n",
    "    return hasFrames\n",
    "\n",
    "def list_files1(directory, extension):\n",
    "    \"\"\"\n",
    "    list_files1: Find files with a certain extension in the directory and return the names in a list\n",
    "            Args:\n",
    "                directory: Directory to be searched\n",
    "                extension: the extension of the files\n",
    "            Returns:\n",
    "                List of files with the extension within the directory\n",
    "    \"\"\"\n",
    "    return list(( (directory + f) for f in listdir(directory) if f.endswith('.' + extension))) \n",
    "    \n",
    "def generate_frames_vid():\n",
    "    \"\"\"\n",
    "    generate_frames_vid: Generates frames for every video in listvideos, and save them in folder with\n",
    "                         name vidName/\n",
    "                    Args:\n",
    "                        listvideos: List containing the path to the video files\n",
    "                    Returns:\n",
    "                        None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        os.mkdir(\"StableFrames\", 755)\n",
    "    except OSError:\n",
    "        pass\n",
    "    try:\n",
    "        os.mkdir(\"StableFrames/videos\", 755)\n",
    "    except OSError:\n",
    "        pass\n",
    "    listvideos = list_files1('videos/','avi')\n",
    "    for video in listvideos:\n",
    "        path = \"StableFrames/\" + video.split('.avi')[0]\n",
    "        try:\n",
    "            os.mkdir(path, 755)\n",
    "        except OSError:\n",
    "            pass\n",
    "        stable_vid_name = 'stable_video.avi'\n",
    "        stabilizer = VidStab(kp_method='DENSE')\n",
    "        stabilizer.stabilize(input_path=video, output_path=stable_vid_name)\n",
    "        sec = 0\n",
    "        frameRate = 0.1 #//it will capture image in each 0.5 second\n",
    "        count=1\n",
    "        success = getFrame(sec,path,stable_vid_name,count)\n",
    "        while success:\n",
    "            count = count + 1\n",
    "            sec = sec + frameRate\n",
    "            sec = round(sec, 2)\n",
    "            success = getFrame(sec,path,stable_vid_name,count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## New contains the frames for every video \n",
    "generate_frames_vid()\n",
    "a = generate_train_testdata(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "new = get_vid_data(a,67)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17% |############                                                            |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Reading and Preprocessing.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done Reading and Preprocessing.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "### get frames for a certain video\n",
    "vid_idx = 2\n",
    "vid1 = new.iloc[:,vid_idx].tolist()\n",
    "vid1_data = read_data(vid1)\n",
    "vid_name = vid1[0].split(\"/\")[2].split(\"_\")[1] ## Get video name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get model\n",
    "m = vid1_data.shape[1]\n",
    "model = unet_initialize((m,m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Classify frames\n",
    "def get_classify_frames(vid1_data, model):\n",
    "    data = np.empty(shape = [1,500,500])\n",
    "    for i in range(vid1_data.shape[0]):\n",
    "        img = vid1_data[i,:,:,0]\n",
    "        preds = unet_classify(model, img)\n",
    "        preds = preds[:,:,2]\n",
    "        preds = preds.reshape(1,500,500)\n",
    "        data = np.append(data,preds, axis = 0)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save classified images\n",
    "def save_imgs(data):\n",
    "    try:\n",
    "        os.mkdir(\"classifyFrames\", 755)\n",
    "    except OSError:\n",
    "        pass\n",
    "    print(data.shape)\n",
    "    for i in range(data.shape[0]):\n",
    "        plt.figure()\n",
    "        plt.imshow(data[i,:,:])\n",
    "        if (i<10):\n",
    "            plt.savefig(\"classifyFrames/img_0{}.png\".format(i))\n",
    "        else:\n",
    "            plt.savefig(\"classifyFrames/img_{}.png\".format(i))\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(69, 500, 500)\n"
     ]
    }
   ],
   "source": [
    "data = get_classify_frames(vid1_data, model)\n",
    "save_imgs(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "os.system(\"ffmpeg -r 10 -i classifyFrames/img_%02d.png {}.avi\".format(vid_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:CP] *",
   "language": "python",
   "name": "conda-env-CP-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
